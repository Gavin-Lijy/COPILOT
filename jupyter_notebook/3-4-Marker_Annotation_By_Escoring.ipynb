{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marker annotation by calculating escore of markers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that we are in Python\n",
    "\n",
    "#### Working directory must contain subdirectories,supp_data\n",
    "\n",
    "#### supp_data/ should contain the files, which are available on Github (github.com/Hsu-Che-Wei/COPILOT):\n",
    "\n",
    "    hvg_integrated.h5 (get it by running through notebook 3-1)  \n",
    "    curated.genes.txt\n",
    "    hvg_ids.txt (get it by running through notebook 3-2)\n",
    "    r_cells.txt\n",
    "    umap50.txt (get it by running through notebook 3-2)\n",
    "    umap.txt (get it by running through notebook 3-2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import all needed functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix\n",
    "from escoring.enrichment_scoring import calculate_escores\n",
    "from escoring.enrichment_scoring import permute, sig_interval\n",
    "from escoring.support_funcs import load_sparse_h5, pairwise_similarities\n",
    "from escoring.support_funcs import sig_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expression matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "HVG = load_sparse_h5(\"counts\",\"./supp_data/hvg_integrated.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(HVG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escoring accepts matrices where rows are cells and columns are genes. So one will need to transpose the matrix if the matrix is gene-by-cell\n",
    "HVG = HVG.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110427, 17513)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HVG.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Markers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"./supp_data/curated.genes.txt\"\n",
    "with open(fname, \"r\") as f:\n",
    "    cols_to_keep = [int(cell.strip(\"\\n\")) for cell in f.readlines()]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "HVG = HVG[:, cols_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110427, 44)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HVG.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"./supp_data/hvg_ids.txt\"\n",
    "with open(fname, \"r\") as f:\n",
    "    hvg_names = [gene.strip(\"\\n\") for gene in f.readlines()]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvg_names = list( hvg_names[i] for i in cols_to_keep )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hvg_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is just the index of cells, in this case, all the cells are considered\n",
    "fname = \"./supp_data/r_cells.txt\" \n",
    "with open(fname, \"r\") as f:\n",
    "    r_cells = [int(cell.strip(\"\\n\")) for cell in f.readlines()]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cells = np.arange(HVG.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cells = r_cells.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110427"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 50 UMAP dimensions for similarity calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "UMAP_50 = np.loadtxt(\"./supp_data/umap50.txt\")  # or load your preferred representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D UMAP for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "UMAP = np.loadtxt(\"./supp_data/umap.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Enrichment scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use RBF-kernel\n",
    "metric = \"rbf\"  \n",
    "gamma = 0.8  # only use if laplacian, sigmoid or rbf and replace by wished value\n",
    "S = pairwise_similarities(UMAP_50, r_cells, metric=metric,\n",
    "                          metric_params={\"gamma\": gamma}  # only use if needed\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110427, 110427)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start enrichment scoring using 32 CPUs\n",
      "Creating process pool\n",
      "Run enrichment scoring\n",
      "Enrichment scoring complete\n"
     ]
    }
   ],
   "source": [
    "# Calculate the enrichment scores\n",
    "escores = calculate_escores(HVG, r_cells, S=S, optim_over=\"rows\", scale_exp=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The escores dataframe is a dataframe of size genes x r_cells. The order of genes is preserved, so you can map them back to the indices of the genes in the original data. Take care here that in Python, counting starts at 0 and not 1. If you need any help here, let me know. Below, I manually set the gene names to the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "escores.index = hvg_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AT4G00490', 'AT1G62510', 'AT5G07990', 'AT5G55250', 'AT1G61590',\n",
       "       'AT4G02090', 'AT3G11550', 'AT2G27370', 'AT5G06200', 'AT5G57620',\n",
       "       'AT5G42180', 'AT1G33090', 'AT3G09330', 'AT5G49270', 'AT1G48930',\n",
       "       'AT1G69240', 'AT1G45545', 'AT4G37160', 'AT1G79840', 'AT2G37260',\n",
       "       'AT1G65310', 'AT1G79430', 'AT5G62940', 'AT2G37090', 'AT5G12870',\n",
       "       'AT3G09070', 'AT5G43810', 'AT5G26930', 'AT3G26120', 'AT3G43270',\n",
       "       'AT1G68470', 'AT1G55440', 'AT1G11330', 'AT1G26790', 'AT3G05180',\n",
       "       'AT3G55930', 'AT5G36880', 'AT1G23210', 'AT5G57640', 'AT3G60650',\n",
       "       'AT1G13620', 'AT1G17400', 'AT1G55200', 'AT5G45210'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "escores.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permute the dataframe. This takes a little while.\n",
    "n = 100  # how many times to permute the dataframe\n",
    "seed = 42  # set this for reproducibility\n",
    "P = permute(HVG, n=n, seed=seed, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate scores for the permuted expression values. Make sure to pass the permuted dataframe and keep all other parameters the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start enrichment scoring using 32 CPUs\n",
      "Creating process pool\n",
      "Run enrichment scoring\n",
      "Enrichment scoring complete\n"
     ]
    }
   ],
   "source": [
    "pscores = calculate_escores(P, r_cells, S=S, optim_over=\"rows\", scale_exp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the significance cut-offs\n",
    "n_sds = 5  # the number of SDs away from the mean for significance\n",
    "cutoffs = sig_interval(pscores, n_sds=n_sds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a dictionary of significant genes per cell\n",
    "sigs = sig_dictionary(escores, cutoffs, retrieve=\"cols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the output\n",
    "df = pd.DataFrame({key: pd.Series(value) for key, value in sigs.items()})\n",
    "df.to_csv(\"./supp_data/escoring.curated.marker.anno.nsds5.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the output\n",
    "escores.to_csv(\"./supp_data/escoring.curated.marker.csv\", encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
